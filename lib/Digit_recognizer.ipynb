{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80414d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44817c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Test/Training data\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df58b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizee Data to be between 1 and 0\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0 # Flatten and normalize\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0 # Flatten and normalize\n",
    "\n",
    "# Matrix of Training Data\n",
    "m,n = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4b2f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_():\n",
    "  W1 = np.random.randn(10,700) * 0.01\n",
    "  b1 = np.zeros((700, 1))\n",
    "  W2 = np.random.randn(10,700) * 0.01\n",
    "  b2 = np.zeros((10, 1))\n",
    "  lr = 0.1 # Learning Rate\n",
    "  return(W1, W2, b1, b2, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a69af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "def ReLu(Z):\n",
    "  return(np.maximum(0,Z))\n",
    "\n",
    "def SoftMax(x):\n",
    "  exp_x = np.exp(x - np.max(x))  \n",
    "  return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "def derv_ReLu(Z):\n",
    "  return(Z > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3339c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagation\n",
    "def fowardprop(W1, W2, b1, b2, X):\n",
    "  Z1 = np.dot(X, W1.T) + b1.T\n",
    "  A1 = ReLu(Z1)\n",
    "  Z2 = np.dot(A1, W2.T) + b2.T\n",
    "  A2 = SoftMax(Z2)\n",
    "  return(A2, A1, Z2, Z1)\n",
    "\n",
    "def backprop(W1, W2, A1, A2, Z1, Y, X):\n",
    "  m = Y.size\n",
    "  # Second Layer\n",
    "  Y_one_hot = np.eye(10)[Y]  # One-hot encoding of labels\n",
    "  dz2 = A2 - Y_one_hot  # Gradient for output layer\n",
    "  dw2 = np.dot(dz2.T, A1) / m\n",
    "  db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "  # First Layer\n",
    "  dz1 = np.dot(dz2, W2) * derv_ReLu(A1)\n",
    "  dw1 = np.dot(dz1.T, X) / m\n",
    "  db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "  return(dw1, dw2, db1, db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18f076a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Parameters\n",
    "def Update(W1, W2, b1, b2, dw1, dw2, db1, db2, lr):\n",
    "  new_W1 = W1 - lr * dw1\n",
    "  new_W2 = W2 - lr * dw2\n",
    "  new_b1 = b1 - lr * db1\n",
    "  new_b2 = b2 - lr * db2\n",
    "  return(new_W1, new_W2, new_b1, new_b2)\n",
    "\n",
    "# Gradient Decent\n",
    "def Get_pred(A2):\n",
    "  return(np.argmax(A2,0))\n",
    "\n",
    "def Pred_accuracy(predictions, test_data):\n",
    "  return(np.sum(predictions == test_data) / test_data.size)\n",
    "\n",
    "def Gradient_decent(train_data, train_labels, iterations):\n",
    "  W1, W2, b1, b2, lr = _init_()\n",
    "  for i in range(iterations):\n",
    "    A2, A1, Z2, Z1 = fowardprop(W1, W2, b1, b2, train_data)\n",
    "    dw1, dw2, db1, db2 = backprop(W1, W2, A1, A2, train_labels, train_data)\n",
    "    W1, W2, b1, b2 = Update(W1, W2, b1, b2, dw1, dw2, db1, db2, lr)\n",
    "    if (i % 10 == 0):\n",
    "      print(\"Iteration: {i}\")\n",
    "      print(\"Accuracy: \", Pred_accuracy(Get_pred(A2), train_labels))\n",
    "  return(W1, W2, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a541eb07",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (60000,784) and (700,10) not aligned: 784 (dim 1) != 700 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Running Model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mGradient_decent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Testing the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m Get_pred(fowardprop(W1, W2, b1, b2, X_test)[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m, in \u001b[0;36mGradient_decent\u001b[1;34m(train_data, train_labels, iterations)\u001b[0m\n\u001b[0;32m     17\u001b[0m W1, W2, b1, b2, lr \u001b[38;5;241m=\u001b[39m _init_()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m---> 19\u001b[0m   A2, A1, Z2, Z1 \u001b[38;5;241m=\u001b[39m \u001b[43mfowardprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m   dw1, dw2, db1, db2 \u001b[38;5;241m=\u001b[39m backprop(W1, W2, A1, A2, train_labels, train_data)\n\u001b[0;32m     21\u001b[0m   W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m Update(W1, W2, b1, b2, dw1, dw2, db1, db2, lr)\n",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m, in \u001b[0;36mfowardprop\u001b[1;34m(W1, W2, b1, b2, X)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfowardprop\u001b[39m(W1, W2, b1, b2, X):\n\u001b[1;32m----> 3\u001b[0m   Z1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b1\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      4\u001b[0m   A1 \u001b[38;5;241m=\u001b[39m ReLu(Z1)\n\u001b[0;32m      5\u001b[0m   Z2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A1, W2\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m b2\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (60000,784) and (700,10) not aligned: 784 (dim 1) != 700 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Running Model\n",
    "W1, W2, b1, b2 = Gradient_decent(X_train, Y_train, 500)\n",
    "\n",
    "# Testing the model\n",
    "test_predictions = Get_pred(fowardprop(W1, W2, b1, b2, X_test)[0])\n",
    "test_accuracy = Pred_accuracy(test_predictions, Y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
